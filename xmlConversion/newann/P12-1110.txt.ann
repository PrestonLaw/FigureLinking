T1	Reference 14813 15011	The list of the features used in our joint model is presented in Table 1, where S01–S05, W01– W21, and T01–05 are taken from Zhang and Clark (2010), and P01–P28 are taken from Huang and Sagae (2010)
A1	RefType T1 Direct
A2	Type T1 Table
A3	Num T1 1
T2	Reference 18596 18628	Table 2: Statistics of datasets.
A4	RefType T2 Direct
A5	Type T2 Table
A6	Num T2 2
T3	Reference 21820 21872	Table 1: Feature templates for the full joint model.
A7	RefType T3 Direct
A8	Type T3 Table
A9	Num T3 1
T4	Reference 23272 23327	The statistics of 96 these splits are shown in Table 2.
A10	RefType T4 Direct
A11	Type T4 Table
A12	Num T4 2
T5	Reference 24576 24672	Table 5 shows that this reimplementation almost reproduces the accuracy of their implementation.
A13	RefType T5 Direct
A14	Type T5 Table
A15	Num T5 5
T6	Reference 27153 27280	Table 3 shows the performance and speed of the full joint model (with no dictionaries) on CTB5c1 with respect to the beam size.
A16	RefType T6 Direct
A17	Type T6 Table
A18	Num T6 3
T7	Reference 27469 27634	Based on this experiment, we set the beam size of SegTagDep to 64 throughout the exper 64 96.28 92.37 74.96 0.48 Table 3: F1 scores and speed (in sentences per sec.)
A19	RefType T7 Direct
A20	Type T7 Table
A21	Num T7 3
T8	Reference 27867 28100	Ta SegTag 97.66 93.61 SegTagDep 97.73 94.46 SegTag(d) 98.18 94.08 SegTagDep(d) 98.26 94.64 Table 5: Final results on CTB5j 76 75 74 ble 4 shows the segmentation, POS tagging, and dependency parsing F1 scores of these models on CTB5c.
A22	RefType T8 Direct
A23	Type T8 Table
A24	Num T8 5
T9	Reference 31986 32105	Table 4: Segmentation, POS tagging, and (unlabeled attachment) dependency F1 scores averaged over five trials on CTB5c.
A25	RefType T9 Direct
A26	Type T9 Table
A27	Num T9 4
T10	Reference 32365 32372	Table 5
A28	RefType T10 Direct
A29	Type T10 Table
A30	Num T10 5
T11	Reference 32373 32485	and Table 6 show a comparison of the segmentation and POS tagging accuracies with other state-of-the-art models.
A31	RefType T11 Direct
A32	Type T11 Table
A33	Num T11 6
T12	Reference 34250 34443	Table 6: Final results on CTB6 and CTB7 accuracies of POS tagging and dependency parsing were remarkably improved by 0.6% and 2.4%, respectively corresponding to 8.3% and 10.2% error reduction.
A34	RefType T12 Direct
A35	Type T12 Table
A36	Num T12 6
T13	Reference 12653 12806	Figure 1 portrays how the states are aligned using the proposed scheme, where a subtree is denoted as a rectangle with its partial index shown inside it.
A37	RefType T13 Direct
A38	Type T13 Figure
A39	Num T13 1
T14	Reference 13793 13940	We also propose to use the features U01–U03, which we found are effective to adjust the character Figure 1: Illustration of the alignment of steps.
A40	RefType T14 Direct
A41	Type T14 Figure
A42	Num T14 1
T15	Reference 25666 25921	(2011), we confirmed that omission of the look-ahead features results in a 0.26% decrease in the parsing accuracy on CTB5d (dev).Figure 2: F1 scores (in %) of SegTagDep on CTB 5c1 w.r.t. the training epoch (x-axis) and parsing feature weights (in legend).
A43	RefType T15 Direct
A44	Type T15 Figure
A45	Num T15 2
T16	Reference 26441 26706	Figure 2 shows the F1 scores of the proposed model (SegTagDep) on CTB5c1 with respect to the training epoch and different parsing feature weights, where “Seg”, “Tag”, and “Dep” respectively denote the F1 scores of word segmentation, POS tagging, and dependency pars
A46	RefType T16 Direct
A47	Type T16 Figure
A48	Num T16 2
T17	Reference 29939 30034	Figure 3: Performance of baseline and joint models w.r.t. the average processing time (in sec.)
A49	RefType T17 Direct
A50	Type T17 Figure
A51	Num T17 3
T18	Reference 30740 30843	Figure 3 shows the performance and processing time comparison of various models and their combinations.
A52	RefType T18 Direct
A53	Type T18 Figure
A54	Num T18 3
