
	
		This research focuses on determining seman­ tic compositionality of word expressions us­ ing word space models (WSMs).
		We discuss previous works employing WSMs and present differences in the proposed approaches which include types of WSMs, corpora, preprocess­ ing techniques, methods for determining com­ positionality, and evaluation testbeds.
		We also present results of our own approach for determining the semantic compositionality based on comparing distributional vectors of expressions and their components.
		The vec­ tors were obtained by Latent Semantic Analy­ sis (LSA) applied to the uk:WaC corpus.
		Our results outperform those of all the participants in the Distributional Semantics and Composi­ tionality (DISCO) 2011 shared task.
	
	
			A word expression is semantically compositional if its meaning can be understood from the literal meaning of its components.
			Therefore, semanti­ cally compositional expressions involve e.g. "small island" or ''hot water"; on the other hand, seman­ tically non-compositional expressions are e.g. "red tape" or "kick the bucket".
			The notion of compositionality is closely related to idiomacy -the higher the compositionality the lower the idiomacy and vice versa (Sag et al., 2002; Baldwin and Kim, 2010).
			Non-compositional expressions are often referred to as Multiword Expressions (MWEs).
			Baldwin and Kim (2010) differentiate the following sub-types of Pavel Pecina Charles University in Prague Faculty of Mathematics and Physics Institute of Formal and Applied Linguistics Prague, Czech Republic pecina@ufal.mff.cuni.cz compositionality: lexical, syntactic, semantic, prag­ matic, and statistical.
			This paper is concerned with semantic compositionality.
			Compositionality as a feature of word expressions is not discrete.
			Instead, expressions populate a con­ tinuum between two extremes: idioms and free word combinations (McCarthy et al., 2003; Bannard et al., 2003; Katz, 2006; Fazly, 2007; Baldwin and Kim, 2010; Biemann and Giesbrecht, 2011).
			Typical ex­ amples of expressions between the two extremes are "zebra crossing" or "blind alley".
			Our research in compositionality is motivated by the hypothesis that a special treatment of se­ mantically non-compositional expressions can im­ prove results in various Natural Language Process­ ing (NPL) tasks, as shown for example by Acosta et al.
			(2011), who utilized MWEs in Information Re­ trieval (IR).
			Besides that, there are other NLP ap­ plications that can benefit from knowing the degree of compositionality of expressions such as machine translation (Carpuat and Diab, 2010), lexicography (Church and Hanks, 1990), word sense disambigua­ tion (Finlayson and Kulkarni, 2011), part-of-speech (POS) tagging and parsing (Seretan, 2008) as listed in Rarnisch (2012).
			The main goal of this paper is to present an anal­ ysis of previous approaches using WSMs for de­ termining the semantic compositionality of expres­ sions.
			The analysis can be found in Section 2.
			A special attention is paid to the evaluation of the pro­ posed models that is described in Section 3.
			Section 4 presents our first intuitive experimental setup and results ofLSA applied to the DISCO 2011 task.
			Sec­ tion 5 concludes the paper.
			42 Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pages 4250, Atlanta, Georgia, 1314 June 2013.
			@2013 Association for Computational Linguistics
	
	
			Expressions Determined by WSMs Several recent works, including lin (1999), Schone and Jurafsky (2001), Baldwin et al.
			(2003), Mc­ Carthy et al.
			(2003), Katz (2006), Johannsen et al.
			(2011), Reddy et al.
			(2011a), and KrCmar et al.
			(2012), show the ability of methods based on WSMs to capture the degree of semantic compositionality of word expressions.
			We analyse the proposed meth­ ods and discuss their differences.
			As further de­ scribed in detail and summarized in Table 1, the ap­ proaches differ in the type of WSMs, corpora, pre­ processing techniques, methods for determining the compositionality, datasets for evaluation, and meth­ ods of evaluation itself.
			Our understanding of WSM is in agreement with Sahlgren (2006): "The word space model is a com­ putational model of word meaning that utilizes the distributional patterns of words collected over large text data to represent semantic similarity between words in terms of spatial proximity".
			For more information on WSMs, see e.g. Turney and Pan­ tel (2010), Jurgens and Stevens (2010), or Sahlgren (2006).
			WSMs and their parameters WSMs can be built by different algorithms including LSA (Landauer and Dumais, 1997), Hyperspace Analogue to Lan­ guage (HAL) (Lund and Burgess, 1996), Random Indexing (Rl) (Sahlgren, 2005), and Correlated Oc­ currence Analogue to Lexical Semantics (COALS) (Rohde et al., 2005).
			Every algorithm has its own specifics and can be configured in different ways.
			The configuration usually involves e.g. the choice of context size, weighting functions, or normaliz­ ing functions.
			While Schone and Jurafsky (2001), Baldwin et al.
			(2003), and Katz (2006) addopted LSA-based approaches, Johannsen et al.
			(2011) and Krcmar et al.
			(2012) employ COALS; the others use their own specific WSMs.
			Corpora and text preprocessing Using differ­ ent corpora and their preprocessing naturally leads to different WSMs.
			The preprocessing can differ e.g. in the choice of used word forms or in re­ moval/retaining of low-frequency words.
			For exam­ ple, while Lin (1999) employs a 125-million-word newspaper corpus, Schone and Jurafsky (2001) use a 6.7-million-word subset of the TREC databases, Baldwin et al.
			(2003) base their experiments on 90 million words from the British National Corpus (Burnard, 2000).
			KrCmar et al.
			(2012), Johannsen et al.
			(2011), and Reddy et al.
			(2011a) use the ukWaC corpus, consisting of 1.9 billion words from web texts (Baroni et al., 2009).
			As for preprocessing, Lin (1999) extracts triples with dependency relation­ ships, Baldwin et al.
			(2003), Reddy et al.
			(2011a), and Krcmar et al.
			(2012) concatenate word lemmas with their POS categories.
			Johannsen et al.
			(2011) use word lemmas and remove low-frequency words while Reddy et al.
			(2011a), for example, keep only frequent content words.
			Methods We have identified three basic methods for determining semantic compositionality: 1) The substitutability-based methods exploit the fact that replacing components of non­ compositional expressions by words which are similar leads to anti-collocations (Pearce, 2002).
			Then, frequency or mutual information of such expressions (anti-collocations) is compared with the frequency or mutual information of the original expressions.
			For example, consider expected occur­ rence counts of ''hot dog" and its anti-collocations such as "warm dog" or "hot terrier''.
			2) The component-based methods, utilized for ex­ ample by Baldwin et al.
			(2003) or Johannsen et al.
			(2011), compare the distributional characteristics of expressions and their components.
			The context vec­ tors expected to be different from each other are e.g. the vector representing the expression "hot dog" and the vector representing the word "dog".
			3) The compositionality-based methods compare two vectors of each analysed expression: the true co-occurrence vector of an expression and the vec­ tur obtained from vectors corresponding to the com­ ponents of the expression using a compositional­ ity function (Reddy et al., 2011a).
			The most com­ mon compositionality functions are vector addition or pointwise vector multiplication (Mitchell and La­ pata, 2008).
			For example, the vectors for ''hot dog" and "hot"E!l"dog" are supposed to be different.
			Evaluation datasets There is still no consensus on how to evaluate models deterntining semantic compositionality.
			However, by examining the dis­ cussed papers, we have observed an increasing ten Pa pe r C or po ra W S M s M et ho ds D at a (ty pe s) E va lu at io n Li n (1 99 9) 12 5 m, tri pl es o w n S Y N V A Ac . di ets ., P/ R Sc ho ne +J ur afs ky (2 00 1) 6.
			7 m T R E C LS A S Y, C Y all ty pe s W N, P/ Rc Ba ld wi n et al.
			(2 00 3) B N C +P O S LS A C T N N, V P W N, P C M cC art hy et al.
			(2 00 3) B N C + G R o w n C Tn P V M A, W N, di ets ., S Ka tz (2 00 6) G N C LS A C Y P N V M A, P/ R, F m Kr cm ar et al.
			(2 01 2) uk W aC +P O S C O A LS S Y A N, V O, S V M A, C R, A P D, C L Jo ha nn se n et al.
			(2 01 1) uk W aC C O A LS S Y, C T A N, V O, S V M A, C R, A P D, C L Re dd y et al.
			(2 01 1a ) uk W aC +P O S o w n C T, C Y N N M A, S, R 2 Table 1: Overview of experiments applying WSMs to determine semantic compositionality of word expressions.
			BNCBritish National Corpus, GR - grammatical relations, GNCGerman newspaper corpus, TRECTREC corpus; SYsubstitutability-based methods, CT- component-based methods, CTn- component-based methods comparing WSM neighbors of expressions and their components, CYcompositionality-based methods; NVAP c. -noun, verb, adjective, adverb combinations, NN - noun-noun, VP - verb-particles, AN - adjective-noun, VO - verb-object, SV - subject-verb, PV - phrasal-verb, PNV - preposition-noun-verb; diets.
			- dictionaries of idioms, WNWordnet, MA - use of mannally annotated data, S - Spearman correlation, PCPearson correlation, CRSpearman and Kendall correlations, APD - average point difference, CL - classification, P/R - Precision/Recall, P/RcPrecisinn/Recall curves, Fm - F measure, R2 - goodness.
			dency to exploit manually annotated data from a specific corpus, ranging from semantically composi­ tional to non-compositional expressions (McCarthy et al., 2003; Katz, 2006; Johannsen et al., 2011; Reddy et al., 2011a; Krcmar et al., 2012).
			This approach, as opposed to the methods based on dictionaries of MWEs (idioms) or Word­ net (Miller, 1995), has the following advantages: Firstly, the classification of a manually annotated data is not binary but finer-grained, enabling the evaluation to be more detailed.
			Secondly, the low­ coverage problem of dictionaries, which originates for example due to the facts that new MWEs still arise or are domain specific, is avoided.1 For exam­ ple, Lin (1999), Schone and Jurafsky (2001), Bald­ win et al.
			(2003) used Wordnet or other dictionary­ type resources.
	
	
			This section discusses evaluation methods includ­ ing average point difference (APD), Spearman and Kendall correlations, and precision of classifica­ tion (PoC) suggested by Biemann and Giesbrecht (2011); Precision/nBest, RecalllnBest and Preci­ sion/Recall curves proposed by Evert (2005); and Average Precision used by Pecina (2009).
			Our eval­ uation is based on the English part of the manu­ ally annotated datasets DISCO 2011 (Biemann and Giesbrecht, 2011), further referred to as DISCO-En­ Gold.
			Disco-En-Gold consists of 349 expressions di­ vided into training (TrainD), validation (ValD), and test data (TestD) manually assigned scores from 0 to 100, indicating the level of compositionality (the lower the score the lower the compositionality and vice versa).
			The expressions are of the following types: adjective-noun (AN), verb-object (YO), and subject-verb (SV).
			Based on the numerical scores, the expressions are also classified into three disjoint classes (coarse scores): low, medium, and high com­ positional.2 A sample of the Disco-En-Gold data is presented in Table 2.
			Comparison of evaluation methods The purpose of the DISCO workshop was to find the best meth­ ods for determining semantic compositionality.
			The participants were asked to create systems capable of assigning the numerical values closest to the ones assigned by the annotators (Gold values).
			The pro­ posed APD evaluation measure is calculated as themean difference between the particular systems' val 1The consequence of using a low-coverage dictionary can cause underestimation of the used method since the dictionary does not have to contain MWEs correctly found by that method.
			2Several expressions with the numerical scores close to the specified thresholds were not classified into any class.
			Type Expression Ns Cs EN_ADLNN blue chip 11 low EN_V_QBJ buck trend 14 low EN_ADLNN open source 49 medium EN_V_OBJ take advantage 57 medium EN_ADLNN red squirrel 90 high EN_V_SUBJ student learn 98 high Table 2: A sample of manually annotated expressions from Disco-En-Gold with their numerical scores (Ns) and coarse scores (Cs).
			ues and the Gold values assigned to the same expres­ sions.
			PoC is defined as the ratio of correct coarse predictions to the number of all the predictions.
			Following KrCmaf et a!.
			(2012), we argue that for the purpose of comparison of the methods, the values assigned to a set of expressions by a certain model are not as important as is the ranking of the expressions (which is not sensitive to the original distribution of compositionality values).
			Similarly as Evert (2005), Pecina (2009), and KrCmar et a!.
			(2012) we adopt evaluation based on ranking (al­ though the measures such as PoC or APD might pro­ vide useful information too).
			Evaluation based on ranking can be realized by measuring ranked correlations (Spearman and Kendall) or Precision/Recall scores and curves com­ monly used e.g. in IR (Manning et a!., 2008).
			In IR, Precision is defined as the ratio of found rele­ vant documents to all the retrieved documents with regards to a user's query.
			Recall is defined as the ra­ tio of found relevant documents to all the relevant documents in a test set to the user's query.
			The Precision/Recall curve is a curve depicting the de­ pendency of Precision upon Recall.
			Analogously, the scheme can be used for evaluation of the meth­ ods finding semantically non-compositional expres­ sions.
			However, estimation of Recall is not possible without knowledge of the correct class3 for every ex­ pression in a corpus.
			To bypass this, Evert (2005) calcnlates Recall with respect to the set of annotated data divided into non-compositional and composi­ tional classes.
			The Precision/nBest, Recall!nBest, and Precision/Recall curves for the LSA experiment 3A semantically non-compositional expression or a seman­ tically compositional expressions described in the following section are depicted in Figures 1 and 2.
			Evert's (2005) curves allow us to visually com­ pare the results of the methods in more detail.
			To facilitate comparison of several methods, we also suggest using average precision (AP) adopted from Pecina (2009), which reduces information provided by a single Precision/Recall curve to one value.
			AP is defined as a mean Precision at all the values of Recall different from zero.
	
	
			LSA is WSM based on the Singular Value De­ composition (SVD) factorization (Deerwester et a!., 1990) applied to the co-occurrence matrix.
			In the matrix, the numbers of word occurrences in speci­ fied contexts4 are stored.
			The row vectors of the ma­ trix capture the word meanings.5 The idea of using SVD is to project vectors corresponding to the words into a lower-dimensional space and thus bring the vectors of words with similar meaning near to each other.
			We built LSA WSM and applied the component­ based method to Disco-En-Gold.
			We used our own modification of the LSA algorithm originally implemented in the S-Space package (Jurgens and Stevens, 2010).
			The modification lies in treating ex­ pressions and handling stopwords.
			Specifically, we added vectors for the examined expressions to WSM in such a way that the original vectors for words were preserved.
			This differentiates our approach e.g. from Baldwin et a!.
			(2003) or Johannsen et a!.
			(2011) who label the expressions ahead of time and build WSMs treating them as single words.
			Treat­ ing the expressions as the single words affects the WSM vectors of their constituents.
			As an example, consider the replacement of occurrences of "short distance" by e.g. the EXP#l23 label.
			This affects the WSM vectors of "short" and "distance" since the numbers of their occurrences and the numbers of contexts they occur in drops.
			Consequently, this also affects the methods for determining the compo­ sitionality which are based upon using the vectors of 4The commonly used contexts for words are documents or the preceding and following words in a specified window.
			5WSMs exploit Harris' distributional hypothesis (Hatris, 1954), which states that semantically similar words tend to ap­ pear in similar contexts.
			expressions' constituents.
			As for treating stopwords, we mapped the trigram expressions containing the determiners "the", "a", or "an" as the middle word to the corresponding hi­ gram expressions without the determiners.
			The intu­ ition is to extract more precise co-occurrence vectors for the YO expressions often containing some inter­ vening determiner.
			As an example, compare the oc­ currences of "reinvent wheel" and "reinvent (deter­ miner) wheel" in the ukWaC corpus which are 27 and 623, respectively, or the occurrences of "cross bridge" and "cross (determiner) bridge" being 50 and 1050, respectively.6 We built LSA WSM from the whole ukWaC POS-tagged corpus for all the word lemmas con­ catenated with their POS tags excluding stopwords.
			We treated the following strings as stopwords: the lemmas with frequency below 50 (omitting low­ frequency words), the strings containing two adja­ cent non-letter characters (omitting strings such as web addresses and sequences of e.g. star symbols), and lemmas with a different POS tag from noun, proper noun, adjective, verb, and adverb (omitting closed-class words).
			As contexts, the entire docu­ ments were used.
			The co-occurrence matrix for words was normal­ ized by applying the log-entropy transformation and reduced to 300 dimensions.
			Using these settings, Landauer and Dumais (1997) obtained the best re­ sults.
			Finally, the co-occurrence vectors of expres­ sions were expressed in the lower-dimensional space of words in a manner analogous to how a user's query is being expressed in lower-dimensional space of documents in IR (Berry eta!., 1995).
			The Disco­ En-Gold expressions were sorted in ascending order by the average cosine similarity between the vec­ tors corresponding to the expressions and the vectors corresponding to their components.
			Evaluation We have not tried to find the optimal parameter settings for the LSA-based model yet.
			Therefore, we present the results on the concate­ nation of TrainD with Va!D giving us TrainVa!D and on TestD.
			The expressions "leading edge" and "broken link" were removed from TestD because they occur in the ukWaC corpus assigned with the 6More precisely, the occurrences were calculated from the POS-tagged parallels of the expressions.
			required POS tags less than 50 times.
			APs with the Spearman and Kendall correlations between the compositionality values assigned by the LSA-based model and the Gold values are depicted in Table 3.
			The Spearman correlations of the LSA model ap­ plied to the whole TrainVa!D and TestD are highly significant with p-values < 0.001.
			For the AP evalu­ ation, the expressions with numerical values less or equal to 50 were classified as non-compositional7 , giving us the ratio of non-compositional expressions in TrainVa!D and TestD equal to 0.26 and 0.20, re­ spectively.
			The Precision/nBest and Recall/nBest graphs corresponding to the LSA-based model ap­ plied to TestD are depicted in Figure 1.
			The Preci­ sion/Recall graphs corresponding to the LSA-based model applied to TrainD and TestD are depicted in Figure 2.
			For comparison, the graphs in Figures 1 and 2 also show the curves corresponding to the evaluation of Pointwise Mutual Information (PM!).8 The co­ occurrence statistics of the expressions in Disco-En­ Gold was extracted from the window of size three, sliding through the whole lemmatized ukWaC cor­ pus.
			Discussion As suggested in Section 3, we com­ pare the results of the methods using Spearman and Kendall correlations, AP, and Everts' curves.
			We present the results of the LSA and PM!
			models alongside the results of the best performing models participating in the DISCO task.
			Namely, Table 3 presents the correlation values of our models, the best performing WSM-based model (Reddy eta!., 2011b), the best performing model based upon as­ sociation measures (Chakraborty eta!., 2011), and random baseline models.
			The poor results achieved by employing PM!
			are similar to the results of random baselines and in ac­ cordance with those of participants of the DISCO workshop (Chakraborty et a!., 2011).
			We hypoth­ esize that the PMI-based model incorrectly assigns low values of semantic compositionality (high val 7Choice of this value can affect the results.
			The value of 50 was chosen since it is the middle value between the manually assigned scores ranging from 0 to 100.
			8PMI is an association measure used to determine the strength of association between two or more words based on their occurrences and co-occurrences in a corpus (Pecina, 2009) . 46 M od el Datasetp A U pAN p-VO p-SV T-AU TAN T-VO T-SV AP-All LS A TrainValD P M I TrainValD baseline TrainValD LSA TestD ReddyWSM TestD StatMix TestD P M I TestD ba sel ine TestD 0 . 4 7 0.54 0.36 0.57 0.32 0.38 0.24 0.44 0.61 0 . 0 20.25 0.29 0.14 0.010.18 0.20 0.10 0.28 0 . 0 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.26 0 . 5 0 0.50 0.56 0.41 0.35 0.36 0.39 0.30 0.53 0 . 35 - - - 0.24 - - - 0 . 33 - - - 0.23 - - - 0.
			080.07 0.130.080.060.04 0.080.07 0.21 0 . 0 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.20 Table 3: The values of AP, Spearman (p) and Kendall (r) correlations between the LSA-based and PMI-based model respectively and the Gold data with regards to the expression type.
			Every zero value in the table corresponds to the theoretically achieved mean value of correlation calculated from the infinite number of correlation values between the ranking of scores assigned by the annotators and the rankings of scores being obtained by a random number genarator.
			ReddyWSM stands for the best performing WSM in the DISCO task (Reddy eta!., 2011b).
			StatMix stands for the best performing system based upon association measures (Chakraborty eta!., 2011).
			Ouly pAll and rAil are available for the models explored by Reddy eta!.
			(2011b) and Chakraborty eta!.
			(2011).
			ues of PMI) to frequently occurring fixed expres­ sions.
			For example, we observed that the calculated values of PMI for "international airport" and "reli­ gious belief" were high.
			To the contrary, our results achieved by employ­ ing the LSA model are statistically significant and better than those of all the participants of the DISCO workshop.
			However, the data set is probably not large enough to provide statistically reliable com­ parison of the methods and it is not clear how re­ liable the dataset itself is (the interannotator agree­ ment was not analyzed) and therefore we can not make any hard conclusions.
	
	
			We analysed the previous works applying WSMs for determining the semantic compositionality of ex­ pressions.
			We discussed and summarized the major­ ity of techniques presented in the papers.
			Our anal­ ysis reveals a large diversity of approaches which leads to incomparable results (Table 1).
			Since it has been shown that WSMs can serve as good predic­ tors of semantic compositionality, we aim to create a comparative study of the approaches.
			Our analysis implies to evaluate the proposed ap­ proaches using human annotated data and evalua­ tion techniques based on ranking.
			Namely, we sug­ gest using Spearman and Kendall correlations, Pre­ cision!nBest, RecalllnBest, Precision/Recall curves, andAP.
			Using the suggested evaluation techniques, we present the results of our first experiments exploit­ ing LSA (Figures 1, 2 and Table 3).
			The results of the LSA-based model, compared with random base­ lines, PMI-based model, and all the WSM-based and statistical-based models proposed by the participants of the DISCO task, are very promising.
	
	
			We thank to Vft Suchomel for providing the ukWaC corpus and the anonymous reviewers for their helpful comments and suggestions.
			The re­ search is supported by Advanced Computing and Information Systems (grant no.
			SGS2013-029) and by the Czech Science Foundation (grant no.
			Pl03112/G084).
			Also, the access to the CERITSC computing facilities provided under the programme Center CERIT Scientific Cloud, part of the Opera­ tional Program Research and Development for Inno­ vations, reg.
			no. CZ.
			1.05/3.2.00/08.0144 is highly appreciated.
	
