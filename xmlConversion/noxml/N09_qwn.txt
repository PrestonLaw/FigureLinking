
	
		This paper presents Q-WordNet, a lexical resource consisting of WordNet senses automatically annotated by positive and negative polarity.
		Polarity classification amounts to decide whether a text (sense, sentence, etc.) may be associated to positive or negative connotations.
		Polarity classification is becoming important for applications such as Opinion Mining and Sentiment Analysis, which facilitates the extraction and analysis of opinions about commercial products, on companies reputation management, brand monitoring, or to track attitudes by mining online forums, blogs, etc. Inspired by work on classification of word senses by polarity (e.g., SentiWordNet), and taking WordNet as a starting point, we build Q-WordNet.
		Instead of applying external tools such as supervised classifiers to annotate WordNet synsets by polarity, we try to effectively maximize the linguistic information contained in WordNet, thereby taking advantage of the human effort undertaken by lexicographers and annotators.
		The resulting resource, Q-WordNet, is a subset of WordNet senses classified as positive and negative.
		In this approach, neutral polarity is seen as the absence of positive or negative polarity.
		The evaluation of Q-WordNet shows an improvement with respect to previous similar resources.
		We believe that Q-WordNet can be used as a starting point for data-driven approaches in Sentiment Analysis.
	
	
			Opinion Mining and Sentiment Analysis are becoming important for determining opinions about commercial products, on companies reputation management, brand monitoring, or to track attitudes by mining online forums, blogs, etc. Given the explosion of information produced and contained via the Internet, it is not possible to keep up with the constant flow of new information by manual methods.
			A typical application of Sentiment Analysis would be tracking what bloggers are saying about brands like Apple, Microsoft, Ford, etc.
			(Symposium, 2010) This paper is focused on polarity classification at word level, namely, it is interested in the connection between lexical semantics and positive and negative connotations associated to a word sense (Strapparava and Mihalcea, 2007).
			Given the appropriate context, almost every word can potentially convey affective meaning.
			Every word, even those that are apparently neutral, can be associated with positive or negative experiences by virtue of their semantic relation with emotional concepts or categories.
			While some acquire polarity connotations in a specific context, there are many others that are just part of a stereotypical common sense knowledge (e.g., ‘cancer’, ‘war’, ‘mum’, ‘angel’, etc.).
			The stereotypical meaning associated to certain words is of particular interest for Sentiment Analysis, as it allows to study the use of words in textual productions (Strapparava and Mihalcea, 2007).
			In this case, the stereotypical or general domain of language use is just seen as another domain, just as the medical domain or the cultural domain, etc. This paper presents Q-WordNet,1 a freely available lexical resource consisting of WordNet senses automatically annotated by polarity.
			Polarity classification amounts to decide whether a text (sense, sentence, etc.) may be associated to positive or negative connotations.
			Inspired by work on classification of word senses by polarity in SentiWordNet (Esuli and Sebastiani, 2006), and taking WordNet as a starting point, we create Q-WordNet.
			Instead of applying external tools such as supervised classifiers to annotate Word- Net synsets by polarity, we try to effectively maximize the linguistic information contained in WordNet, thereby taking advantage of the human effort undertaken by lexicographers and annotators.
			The evaluation of Q-WordNet as a binary classification task shows good improvement with respect to SentiWordNet.
			However, we would like to stress that Q-WordNet is not a finished resource.
			Although it can be used in its current form for data-driven Sentiment Analysis (Pang et al., 2002; Pang and Lee, 2004; Kim and Hovy, 2004; Popescu and Etzioni, 2005; Su and Markert, 2009; DanescuNiculescu- Mizil et al., 2009), or for lexical sentiment analysis tasks (Strapparava and Mihalcea, 2007; Su and Markert, 2009), it could also be used as a training set for supervised classifiers that would subsequently be applied for the improvement of Q-WordNet.
			Next section reviews previous related work on Sentiment Analysis and, in particular, on polarity classification.
			Section 3.
			describes the approach used to automatically annotated WordNet senses by positive and negative polarity.
			The resulting lexical resource is evaluated in section 4.
			and we 1 http://www.rodrigoagerri.net/computational-linguistics/sentiment-analysis finish with some concluding remarks and future work in section 5.
	
	
			There is a large amount of work on Opinion Mining at document level focusing on the automatic analysis of commercial and cultural products (Pang and Lee, 2004; DanescuNiculescu-Mizil et al., 2009).
			Other previous approaches aim at determining the subjectivity of sentences by means of terms that are markers of opinionated content (Kim and Hovy, 2004; Takamura et al., 2005).
			These approaches also classify subjective words by their polarity.
			Note that they classify words instead of senses, which means that they are not able to capture the fact that a word may be used to express various senses of which some of them could have different polarities.
			There seems to be an assumption in these works that polarity classification (to determine whether the opinion expressed by a word sense, sentence or text is positive or negative) actually depends on subjectivity detection.
			In other words, that prior to the task of assigning polarity we need to determine whether it is objective (factual) or subjective (opinion).
			From this point of view, only those expressions deemed to be subjective are classified by polarity (Kim and Hovy, 2004; Takamura et al., 2005).
			However, it has been argued that this would leave out all those expressions that are suitable to be classified as objectively positive or negative (Su and Markert, 2008).
			Clear cases are those denoting illnesses, such as ‘cancer’, ‘tuberculosis’, etc., which stereotypically carry negative associations.
			Note that, as it was mentioned in the introduction, these senses may not be negative in a medical domain.
			We therefore take the “general domain” to be a stereotypical domain, which means that our classification may need to be refined for its use in other domains.
			There are also other approaches to subjectivity recognition that work at sense level: Su and Markert (2008; 2009) and Wiebe and Milhacea (2006) annotate subjectivity and objectivity of word senses without assuming previous subjectivity classification.
			Closer to our work, Esuli and Sebastiani (2006) annotate WordNet 2.0 senses by using a ternary polarity classification (positive, negative and objective) in which each polarity value is assigned a numerical score in such a way that the sum of the three scores is 1.0.
			The final resource provides the positive and negative scores for each synset from which the objective score is then obtained by calculating 1 - (PosScore + NegScore).
			In order to build SentiWordNet, they start by selecting the synsets of 14 paradigmatic positive and negative terms used as seed (Turney and Littman, 2003).
			They are then iteratively extended by means of lexical relations as defined in WordNet, following the construction of WordNet-Affect (Strapparava and Valitutti, 2004).
			After hand-collecting a number of labelled terms from other resources, they iteratively add the the synsets reachable by navigating the relations of direct antonymy, similarity, derived-from, pertains-to, attribute, also-see.
			In SentiWordNet, the objective synsets are those that do not belong to the positive or negative synsets, and that contain terms which are not marked as either positive or negative by Stone et al.
			(1966).
			Every synset is then given a VSM (Salton, 1983) representation (cosine-normalized tf∗ idf ) to its gloss, which is taken as the textual representa tion of its meaning.
			The vectorial representations are fed to a standard supervised learner.
			Finally, the tokens that are in both positive and negative categories are classified as objective.
			They trained 7 supervised classifiers using this method which are used to assign polarity and objectivity scores to WordNet senses.
			An evaluation of their classification is provided as an estimation of its Mean Squared Error (Esuli, 2008).
			They assume that those senses that are not classified as either positive or negative are in fact objective, namely, expressing factual content.
			In other words, every word that is not associated with a positive or negative connotation is not expressing an opinion.
			As mentioned earlier, we do not agree with this assumption as there might be word senses objectively associated with positive or negative connotations.
			Thus, the work presented in this paper focuses on the classification of WordNet senses by their polarity regardless of whether they express subjective opinions or factual information.
			Unlike SentiWordNet (Esuli and Sebastiani, 2006), which is built using supervised classifiers to annotate Word- Net senses, we exploit the linguistic information (provided by human annotators) contained in WordNet itself and build our resource using an unsupervised method.
	
	
			Our approach to classifying WordNet senses by polarity is based on the view of polarity as an association of a positive or a negative quality to something or to someone.
			The idea is to: 1.
			Link a sense to an attribute of a quality (e.g., positive.
			or negative).
			2.
			Devise, if needed, a procedure to quantify such asso-.
			ciation, by using either similarity measures (Agirre et al., 2009), or confidence scores by establishing a ranking in our classification (Esuli and Sebastiani, 2007).
			The rest of the paper focuses on the first point, namely, on building a lexical resource based on WordNet with its senses classified by polarity.
			3.1.
			Rationale.
			Assigning polarity to a word sense can be formulated as a binary classification task.
			This differs from SentiWord- Net in the sense that positive or negative associations are assigned to word senses at a certain level by means of a graded classification.
			Although it is reasonable to acknowledge the fact that polarity classification is somewhat dependent on context by providing a graded classification, it is also important to bear in mind the fact that polarity classification should be practical, operative and easy to use in a given domain.
			Our own experience trying to use SentiWordNet is that the graded classification needs to be collapsed into absolute categories prior to using the resource.
			In other cases, it is actually difficult to do such simplification.
			For example, table 1 shows the SentiwordNet classification of the synset good#a#15.
			S y n s e t Po s N e g O bj go od #a #1 5 0.
			25 0.
			37 5 0.
			37 5 Table 1: good#a#15 SentiWN scores.
			This example shows just how difficult using such classification can be.
			It also shows that, as we argued in the introduction, a synset can be objectively positive.
			This is made even clearer by looking at the lemma names, gloss and examples of synset good#a#15 listed in table 2.
			S y n s e t L e m m a s G l o s s go od #a #1 5 ‘g oo d’ ‘w ell ’ ‘re sul tin g fav or ab ly’ Example 1: it’s a good thing that I wasn’t there E x a m pl e 2 : it i s g o o d t h a t y o u s t a y e d E x a m pl e 3 : it i s w e ll t h a t n o o n e s a w y o u E x a m pl e 4 : a ll’ s w e ll th at e n d s w e ll Table 2: good#a#15 gloss and examples.
			Our aim would therefore be to associate such synsets with the attribute of a quality, instead of assigning them a numerical graded score.
			In our approach those synsets that are not positive or negative will be considered neutral (as opposed to objective or subjective).
			Furthermore, those synsets that are classified by our method as both positive and negative will be discarded, as opposed to SentiWordNet, that consider them objectives.
			The discarded synsets represent a shortcoming of our approach.
			In other words, our approach will need to be improved in order to better classify those synsets into positives or negatives (or to ignore them if that is not possible).
			In addition to the qualitative aspect of our approach, our objective is also to maximize the human effort employed in building WordNet, and see how far we can go by walking WordNet collecting positive and negative senses as we pass by.
			Of course, the issue here is where to start walking.
			Instead of starting with a list of manually collected seed terms, we will just rely on the linguistic information contained in WordNet.
			Given that polarity is seen as the attribute of a quality associated to synsets, we will simply start from the quality synset contained in WordNet.
			There are five noun quality senses in WordNet, two of which contain attribute relations (to adjectives).
			From the synset quality#n#01 the attribute relation takes us to positive#a#01, negative#a#01, good#a#01 and bad#a#01.
			quality#n#02 leads to the attributes superior#a#01 and inferior#a#02.
			Starting by the attributes of quality fits well with our intuition that assigning polarity to a linguistic expression can be seen as associating it with a quality attribute.
			We therefore take these six synsets, expressing positive and negative qualities, to be the departure of our algorithm.
			The following step is to algorithmically walk through every WordNet relation collecting (i.e., annotating) those synsets that are accessible from the seeds.
			The resulting resource is Q-WordNet (Q from the quality synset), the set of WordNet synsets classified by positive or negative polarity as they are accessible through WordNet’s relations.
			Before going into specific details, it is quite clear that if we want Q-WordNet to be proportionate in terms of part-of speech (POS), then we may not only need to walk through WordNet senses, but also to jump from one POS to the other.
			Otherwise, as our seeds are adjectives (attributes of nouns are adjectives), we risk to obtain a classification consisting mainly of adjectives plus few nouns, verbs and adverbs.
			This the reason why every WordNet relation is walked, not just those that preserve the affective content (Strapparava and Valitutti, 2004).
			Our approach has been applied to WordNet versions 1.6, 1.7, 2.0 and 3.0.
			Henceforth, when mentioning WordNet we will be referring indistinctly to any of the four versions, unless it is specified otherwise.
			3.2.
			Walking WordNet.
			Walking through every relation will allow us to jump from adjectives to other POS.
			Table 3 lists those relations that allow us to extract synsets of different POS starting from the initial set of adjectives which are attributes of the quality synset.
			The directionality of the relation is indicated by ← and →.
			inp ut P O S rel ati on out put P O S ad j ← att rib ute → no un ad j de riv ed fro m → no un & ve rb no un pe rtai ny m → ad j no un de riv ed fro m → adj & ver b & no un ve rb ad v & ad j de riv ed fro m → pe rtai ny m → adj & no un ad v Table 3: Jumping POS in WordNet.
			Using every available WordNet relation and their glosses in the way described above is bound to cause a lot of noise in the classified data which will translate in large numbers of false positives and false negatives.
			In order to prevent this, every synset that appear at both positive and negative categories, at every step in the algorithm, is filtered.
			Even though this method will discard a large number of synsets, we want Q-WordNet to be as clean as possible.
			Filtering at every step from relation to relation will allow to minimize the number of false positives and negatives present in the resource.
			The algorithm to build Q-WordNet starts at the attributes of quality#n#01 and quality#n#02, which are adjectives.
			We perform 10 iterations over the also see relation (our experiments showed that more than 10 iterations creates too much noise).
			We then go to similar-to.
			From all the collected adjectives, we get their attributes, which allows us to move to nouns.
			We obtain nouns and verbs from adjectives through the lexical relation derived-from.
			We then use hyperonymy, hyponymy, pertainyms, derived-from, verb- group and cause (plus the antonym relation at every step to filter false positives and negatives) to nouns and verbs.
			At this stage, it is easy to see that no adverbs are extracted using our methodology.
			This is because the only relation linking adverbs to other POS in WordNet is through the pertainym lexical relation via adjectives.
			However, the per- tainym relation is directional from adverbs to adjectives so we cannot start from the already extracted adjectives.
			Instead, the adverbs in Q-WordNet are extracted from a re verse application of the pertainym relation to adjectives (adverbs are pertainyms of adjectives).
			We proceed by extracting the lemmas of every adverb that is matched to the intersection of every lemma’s adjective already extracted by our algorithm and the pertainyms of the adverb’s lemmas (which are adjectives’ lemmas).
			Applying this to WordNet 1.6, 1.7, 2.0 and 3.0 we obtain the following figures: Table 4: Total number of synsets classified by sentiment.
			We obtain 7402 positive and 8108 negative synsets from the application of our method to WordNet 3.0, whereas for WordNet 2.0 we obtain 2884 as positive and 2100 as negative.
			As a comparison, WordNet-Affect consists of 2874 synsets (admittedly, fine-grained affective annotation is much harder than polarity), and SentiWordNet contains 35409 synsets labelled as either positive or negative at any level (0.1251.0), even though a synset might be labelled as objective, positive and negative at the same time.
			This means that we cannot straightforwardly compare Q- WordNet to SentiWordNet (built from WordNet 2.0) because their classification is graded at a specific level.
			In the following section we will see that as the polarity confidence scores get higher in SentiWordNet, the number of polarity- classified synsets shrinks significantly.
			In other words, as the polarity graded scores are lower, the number of polarity- classified synsets grows quite large (35049 synsets) but at the cost of a huge increase in false positives and negatives.
			We discuss this and other issues in the next section, which describes the results of the evaluation of Q-WordNet and how it compares to SentiWordNet 1.0.
	
	
			In order to evaluate Q-WordNet and compare it with SentiWordNet, we use MicroWnOp as testset (Esuli and Sebastiani, 2006).
			The corpus has originally been annotated by the providers (Esuli and Sebastiani, 2007) with scores for positive, negative and objective/no polarity, thus a mixture of subjectivity and polarity annotation.
			As Mi- croWnOp is annotated using SentiWordNet’s graded three score method, some modifications are required in order to be used for Q-WordNet’s evaluation.
			4.1.
			Preparing Testset.
			First, all objective synsets are removed, as we want to evaluate positive and negative cases in a binary classification task.
			This results in a final testset of 737 synsets at the lowest polarity score (0.125).
			As it is the case with SentiWordNet 1.0, the higher the confidence score, the lower the number of synsets at that confidence level.
			For example, at the 0.375 level, the number of synsets classified by polarity is 527.
			Second, some parts of MicroWnOp were annotated by more than one annotator.
			In order to deal with these cases, the polarity scores were averaged.
			As SentiWordNet 1.0 is based on WordNet 2.0, we will compare it with the version of Q-WordNet version built from WordNet 2.0.
			Finally, as both the testset and SentiWordNet 1.0 are graded, we will be performing a comparison between Q-WordNet and SentiWordNet for every score of the scale.
			This means that to evaluate the systems using the testset containing all synsets annotated by polarity (727), we will be using SentiWordNet 1.0 with polarity synset at 0.125 level, etc. As Q-WordNet uses a qualitative binary classification, it remains unchanged.
			After several experiments this method of preparing the evaluation is the one for which SentiWord- Net obtains the best results.
			It should also be clear that we do not penalize (as false positive or negative) the fact that sometimes SentiWordNet gives both positive and negative scores to the same synset.
			The systems are evaluated in a binary classification task in terms of precision (P), recall (R) and F1 measure.
			We also measure accuracy (A).
			This evaluation method means that systems will get lower results as the number of false positives and negatives increases.
			Results are compared using the McNemar significance test at the 0.05 significance level.
			4.2.
			Results.
			Table 5 shows the results for each resource.
			Furthermore, the right-hand size columns show the polarity graded scores at which both SentiWordNet and the testset are considered and the number total synsets annotated as either positive or negative having each graded score as threshold.
			For example, SentiWordNet 1.0 consists of 4923 synsets with the minimum polarity score of 0.625.
			As Q-WordNet does not provide graded scores it always consists of 4984 synsets.
			P o s i t i v e sQ WordNet SentiWN 1.0 P R F1 P R F1 p @ s y n .84 .95 .89 .66 .68 .67 .12 5 35 04 9 .89 .95 .92 .77 .76 .76 .2 5 22 85 5 .94 .97 .95 .84 .87 .85 .37 5 14 61 1 .94 .97 .96 .88 .93 .90 .5 0 94 45 .96 .96 .96 .88 .90 .89 .62 5 49 23 .96 .97 .97 .96 1 .96 .7 5 20 27 .96 1 .98 1 1 1 .87 5 4 6 6 .98 1 .99 1 1 1 1 1 4 N e g a t i v e sQ WordNet SentiWN 1.0 P R F1 P R F1 p @ s y n .89 .67 .76 .63 .60 .62 .12 5 35 04 9 .88 .77 .83 .70 .71 .70 .2 5 22 85 5 .93 .86 .89 .83 .78 .80 .37 5 14 61 1 .92 .88 .90 .88 .80 .84 .5 0 94 45 .91 .91 .91 .84 .80 .82 .62 5 49 23 .94 .91 .92 1 .84 .91 .7 5 20 27 1 .93 .97 1 1 1 .87 5 4 6 6 1 .96 .98 1 1 1 1 1 4 Table 5: Results for Positive and Negative Classes.The results of table 5 show that Q-WordNet clearly out performs SentiWordNet 1.0 up to the 0.75 level (the differences are statistically significant) where there are not clear differences between the two resources.
			It should be noted however that, at polarity scores 0.75, SentiWordNet (2027) is less than half the size with respect to Q-WordNet (4984); at 0.875 level SentiWordNet is ten times smaller.
			When SentiWordNet is of similar size to Q-WordNet (at 0.625 polarity score) or larger, the results are significantly better for Q-WordNet.
			Moreover, the high scores of both resources at the highest polarity confidence levels is probably due to the reduced size of the testset, just 238 and 195 synsets respectively.
			As Q-WordNet does not at this state quantify or rank the polarity annotation, it gets evaluated on all 4984 synsets at every level, which in principle should have made it more vulnerable to false positive and negatives for the higher confidence scores.
			However, the differences between SentiWordNet and Q-WordNet at 0.875 and 1.0 levels are not statistically significant.
			The differences (or lack thereof) are clearer in figure 1.
			Another issue worth mentioning is the fact that results are lower for the negative class, especially in terms of recall.
			These results are confirmed by the Accuracy scores shown in table 6.
			A c c u r a c y P o s / N e gQ W N Se nti W N 1.
			0 Se nti W N Sy ns et s po lar ity @ . 8 5 .6 5 35 04 9 .1 25 . 8 9 .7 4 22 85 5 .2 5 . 9 3 .8 3 14 61 1 .3 75 . 9 4 .8 8 94 45 .5 . 9 5 .8 6 49 23 .6 25 . 9 5 .9 4 20 27 .7 5 . 9 8 1 46 6 .8 75 . 9 9 1 14 1 Table 6: Measuring Accuracy.
			Figure 1 represents the evolution in accuracy of both Q- WordNet and SentiWordNet 1.0.
			The square pointed line represents SentiWordNet whereas the diamond one refers to Q-WordNet.
			The results clearly show that as the level of confidence decreases, Q-WordNet’s results do not degrade as much as those of SentiWordNet, which means that we have a lower number of false positives and negatives.
			Even for a evaluation on a small corpus such as MicroWnOp, we believe that the results are encouraging, and show the efectiveness of the strict filtering of synsets during the annotation process.
			Given that Q-WordNet is by no means a finished resource, we believe that these results show excellent potential to carry on enriching it with a linguistic processing of glosses (perhaps using disambiguated glosses).
			It can also be used as training data for data-driven approaches to Sentiment Analysis or to build classifiers which could be later be deployed on WordNet for a larger and richer polarity annotated resource.
			Our procedure is also suitable to be combined with similarity and ranking algorithms to offer graded polarity as required by any particular applications.
			Finally, note that as it entirely depends on WordNet structure, the algorithm is directly applicable to any other WordNets available in other languages.
			Figure 1: Accuracy Trends on MicroWnOp Corpus.
	
	

