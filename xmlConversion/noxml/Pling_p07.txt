
	
		This paper describes a push-the-button MT system combination toolkit.
		The combination is based on the creation of a lattice made on several confusion networks (CN) connected together.
		This lattice is then decoded with a token-pass decoder to provide the best and/or n-best outputs.
		Each CN is built using a modiﬁed version of the TERp tool.
		The toolkit is made of several scripts along a core program developed in Java.
		It is totally conﬁgurable and the parameters can be tuned quite easily.
	
	
			Machine translation (MT) system combination has taken a great importance these past few years.
			This is mainly due to the fact that single systems achieved good performance and the possibility of taking the most of their complementarity in a system combination framework is very attractive.
			Many techniques can be used for system combination.
			One concerns hypothesis selection using nbest list reranking based on various features as described in (Hildebrand and Vogel, 2009).
			Another approach is to consider source text and systems outputs as bitext and train a new SMT system on these data (Chen et al., 2009).
			In this paper, a system combination based on confusion network (CN) is described.
			This approach is not new, and numerous publications are available on that subject, see for example, (Rosti et al., 2007); (Shen et al., 2008); (Karakos et al., 2008) and (Leusch et al., 2009).
			Such an approach is presented in Figure 1.
			The protocol can be decomposed into three steps : © 2010 PBML.
			All rights reserved.
			Corresponding author: loic.barrault@gmail.com Cite as: Loïc Barrault.
			MANY: Open Source Machine Translation System Combination.
			The Prague Bulletin of Mathematical Linguistics No. 93, 2010, pp.
			147–155.
			ISBN 97880-9041754-0.
			doi: 10.2478/v10108010-0001-y.
			P 010 System 0 1-best output TERp alignment LM C N best hypo System 1 1-best output TERp CN alignment CN Merge Lattice DECODE output {nbest list System M 1-best output T E R p a l i g n m e n t Figure 1.
			MT system combination.
			Each 1-best outputs are aligned to create as many Confusion Networks which are connected together to form a lattice.
			This lattice is then decoded with a token-pass decoder using a Language Model to produce 1-best and/or n-best hypotheses.
			1.
			1-best hypotheses from all M systems are aligned in order to build confusion networks.
	
	
			3.
			A language model is used to decode the resulting lattice and the best hypothesis is generated.
			Section 2.1 describes the alignment process and in particular the new features added to TERp in order to be enable alignment of an hypothesis against a CN.
			The decoder is presented in section 3.
			Some example results obtained at the IWSLT’09 evaluation campaign are given in section 5.
			Finally, a description of the toolkit is given in section 6.
			2. Hypotheses alignment and confusion network generation.
			The goal of this step is to put the words provided by diﬀerent systems in competition with each other inside a confusion network (Mangu et al., 1999).
			For each segment, the best hypotheses of M − 1 systems are aligned against the last one used as backbone.
			A modiﬁed version of the TERp tool (Snover et al., 2009a)(Snover et al., 2009b) is used to generate a confusion network (see section 2.1 for de tails).
			This is done by incrementally adding the hypotheses to the CN.
			The hypotheses are added to the backbone beginning with the nearest (in terms of TER) and ending with the more distant one.
			This diﬀers from the result of (Rosti et al., 2007) where the nearest hypothesis is computed at each step, which is supposed to be better.
			M confusion networks are generated in this way.
			Then all the confusion networks are connected into a single lattice by adding a ﬁrst and last node.
			The probability of the 148 L. Barrault Open Source MT System Combination (147–155) ﬁrst arcs (later named priors) must reﬂect how well such system provides a well structured hypothesis.
			2.1.
			Modiﬁed TERp.
			The modiﬁed TERp is based on TERp v0.1 and is written in Java.
			Some classes have been modiﬁed and new ones were created to add some functionalities such as alignment between a sentence and a confusion network.
			This has been done by modifying the data structure and extending some heuristic to ﬁnd better alignment.
			When using relaxed constraints with TERp, the shift heuristics allow a block of words to be moved if it matches (or is a paraphrase of) another block of words somewhere else.
			Shifts are also allowed when a stem or synonym is found somewhere else.
			When considering confusion networks, the same heuristics are applied except that the block of words must match (be a paraphrase, synonyms or stem of) one of the sequence of words represented in the CN.
			An example of such a case is presented in ﬁgure 2.
			In ﬁ Is the dinner included ? Match Paraphrase Match Match Supper is included ? the dinner Is included ? supper NULL Sub Ins Sub Sub Match Match Do you have calculated dinner ? Is NULL the dinner included supper ? Do you have NULL calculated Figure 2.
			Incremental alignment with TERp resulting in a confusion network.
			a switch of block of word.
			However, the word supper is aligned with the word the because no rule is used in order to make inside-paraphrase word alignment, yet !
			(see section 6.4 for future features).
			149 PBML 93 JANUARY 2010 In addition to the confusion network generation, the possibility of using scores on words has been added, which can be very useful during the decoding.
			For the moment, these scores must be computed separately from MANY.
			The underlying idea is to provide an option to include conﬁdence measure at word level, though it can be computed at any level (see for example, (Ueﬀing and Ney, 2005)).
			In this version of the software, the scores are equal to the priors of the systems.
			However, these values can be modiﬁed in the conﬁguration ﬁle.
	
	
			The decoder is based on the token pass decoding algorithm (see for example (Young et al., 1989)).
			The principle of this decoder is to propagate tokens over the lattice and accumulate various scores into a global score for each hypotheses.
			The scores used to evaluate the hypotheses are the following : • the system score : this replace the score of the translation model.
			Until now, the words given by all systems have the same probability which are equal to their priors, but any conﬁdence measure can be used at this step.
			• the language model (LM) probability.
			• a fudge factor to balance the probabilities provided in the lattice with regard to those given by the language model.• a null-arc penalty : this penalty avoids to always go through null-arcs encoun tered in the lattice.
			• a length penalty : this score helps to generate correctly sized hypotheses.
			The probabilities computed in the decoder can be expressed as follow : log(PW ) = Len(W) ∑ n=0 [log(Pws (n)) + αPlm (n)] (1) +Lenpen (W) + Nullpen (W) where Len(W) is the length of the hypothesis, Pws (n) is the score of the nth word in the lattice, Plm (n) is its LM probability, α is the fudge factor, Lenpen (W) is the length penalty of the word sequence and Nullpen (W) is the penalty associated with the number of null-arcs crossed to obtain the hypothesis.
			At the beginning, only one token is created at the ﬁrst node of the lattice.
			Then this token spread over the consecutive nodes, accumulating the score on the arc it crosses, the language model probability of the word sequence generated so far and null or length penalty if applicable.
			The number of tokens can increase really quickly to cover the whole lattice, and, in order to keep it tractable, only the Nmax best tokens are kept (the others are discarded), where Nmax can be conﬁgured in the conﬁguration ﬁle.
			Other methods to restrict the number of tokens (like pruning based on score or other heuristics) can easily be implemented in this software, but this is not done already.
			150 L. Barrault Open Source MT System Combination (147–155) 3.1.
			Technical details about the token pass decoder.
			This software is based on the Sphinx4 library and is highly conﬁgurable (Walker et al., 2004).
			The maximum number of tokens being considered during decoding, the fudge factor, the null-arc penalty and the length penalty can all be set within the xml conﬁguration ﬁle.
			This is useful for tuning (see the conﬁg ﬁle generator description in section 6.2).
			The probabilities which are manipulated within the decoder are all obtained from the LogMath class which ensures the consistency of the values.
			3.2.
			Language model.
			There are two ways of loading a LM with this software.
			The ﬁrst solution is to use the LargeTrigramModel class, but as its name tells us, only a 3-gram model can be loaded with this class.
			The second and easiest way is to use a language model hosted on a lm-server.
			This kind of LM can be accessed via the LanguageModelOnServer class which is based on the generic LanguageModel class from the Sphinx4 library.
			This allows us to load a n-gram LM with n higher than 3, which is not possible with a standard LM class in Sphinx4 yet (it is currently being done).
			In addition, the Dictionary interface has been extended in order to be able to load a simple dictionary containing all the words known by the LM (no need to know the diﬀerent pronunciations of each words in this case).
			As the language model interface is also written in java and is using the Sphinx4 library, one could easily write a new class to load a LM in a proprietary ﬁle format.
	
	
			There is a lot of parameters which can be tuned in MANY.
			The edit costs of the modiﬁed TERp, the prior costs of each systems in the lattice, the fudge, null-arc penalty and length penalty for the decoder.
			This can easily been done by generating conﬁgu- ration ﬁles (with the help of genSphinxConﬁg.pl, see section 6.3).
			Parameters for mod- iﬁed TERp, for the decoder and systems weights are currently tuned together.
			The separate tuning of TERp and decoder parameters is an ongoing work, and I could not say whether it is preferable or not yet.
			Any method can then be used to provide new values for these parameters.
			As anexample, we are using Condor (Berghen and Bersini, 2005) to optimize those param eters.
	
	
			MANY software has been used for the IWSLT’09 evaluation campaign.
			Table 1 presents the results obtained with this approach.
			The SMT system is based on MOSES, 151 PBML 93 JANUARY 2010 the SPE system corresponds to a rule-based system from SYSTRAN whose outputs have been corrected by a SMT system and the Hierarchical is based on Joshua.
			Sy ste ms Ar ab ic/ E ng lis h D ev 7 Test09.
			C hi ne se/ E ng lis h De v7 Test09 S M T C SL M 54 .7 5 50.35 41.
			71 36.04 SP E C SL M 48 .13 41.
			23 38.53 Hi era rc hi cal 54 .0 0 49.06 39.
			78 31.89 S M T CS L M + SP E C SL M + tu ni ng 42.
			55 40.14 43.
			06 39.46 S M T CS L M + Hi er.
			+ tu ni ng 55 .8 9 50.86 57 .0 1 51.74 Table 1.
			Results of system combination on Dev7 (development) corpus and Test09, the oﬃcial test corpus of IWSLT’09 evaluation campaign.
			In these task, the system combination approach yielded +1.39 BLEU on Ar/En and +1.7 BLEU on Zh/En.
			One observation is that tuning parameters did not provided better results for Zh/En.
	
	
			The software is available at the following address : http://wwwlium.univlemans.fr/~barrault/MANY 6.1.
			Data.
			The software takes several ﬁles as input (which are supposed to be synchronized1 ) containing the 1-best hypothesis of all systems, one sentence per line.
			These hypotheses can contain foreign words if no translation have been found for them, and they will be considered as unknown words during the decoding step.
			6.2.
			Conﬁguration ﬁle.
			The conﬁguration ﬁle is an xml ﬁle similar to those used with Sphinx4.
			<component name="decoder" type="edu.loic.decoder.TokenPassDecoder"> <property name="dictionary" value="dictionary"/> <property name="logMath" value="logMath"/> <property name="logLevel" value="INFO"/> 1 i.e. each nth line is the translation of the same source sentence 152 L. Barrault Open Source MT System Combination (147–155) <property name="lmonserver" value="lmonserver"/> <property name="fudge" value="0.2"/> <!-- This value is multiplied by 10 in the software --> <property name="null_penalty" value="0.3"/> <property name="length_penalty" value="0.5"/> <!-- This value is multiplied by 10 in the software --> </component> This part allows us to conﬁgure the decoder parameters such and more particularly the fudge factor, the null-arc penalty and the length penalty.
			<component name="lmonserver" type="edu.cmu.sphinx.linguist.language.ngram.LanguageModelOnServer"> <property name="lmserverport" value="1234"/> <property name="lmserverhost" value="machine1"/> <property name="maxDepth" value="4"/> <property name="logMath" value="logMath"/> </component> This part conﬁgures the LM class which will connect to the lm-server hosted on ma- chine1 on port ”1234”.
			The maxDepth ﬁeld correspond to the depth of the LM loaded on the server.
			<component name="MANY" type="edu.lium.mt.MANY"> <property name="decoder" value="decoder"/> <property name="terp" value="terp"/> <property name="output" value="output.many"/> <property name="priors" value="4.0e01 4.0e01 2.0e01"/> <property name="hypotheses" value="hyp0.id hyp1.id hyp2.id" /> <property name="hyps_scores" value="hyp0_sc.id hyp1_sc.id hyp2_sc.id" /> <property name="costs" value="1.0 1.0 1.0 1.0 1.0 0.0 1.0" /> <!-- del stem syn ins sub match shift--> <property name="terpParams" value="terp.params"/> <property name="wordnet" value="/opt/mt/WordNet3.0/dict/"/> <property name="shift_word_stop_list" value="/opt/mt/terp/terp.v1/data/shift_word_stop_list.txt"/> <property name="paraphrases" value="/opt/mt/terp/terp.v1/data/phrases.db"/> </component> This part is the core part.
			It conﬁgures the various ﬁles to combine, the costs for TERp, the location of WordNet and the paraphrases table (also for TERp).
			The priors can be set here and are used in the lattice.
			6.3.
			Scripts.
			The main script is called Many.sh.
			Some parameters have to be set inside this script in order to run a system combination experiments.
			The reader should refer to the readme ﬁle provided with the software.
			Each input sentence (as well as the corresponding word scores) must have an id which is of the following form : [set][doc.##][sent] The shell script add_id.sh is in charge of adding such an id to the input data (called in the Many.sh script).
			The perl script genSphinxConﬁg.pl is used to generate a new conﬁg ﬁle with speciﬁc values.
			This is very useful for generating a new conﬁg ﬁle with parameters estimated by a certain optimization procedure.
			6.4.
			Future features.
			Several features are planned to be added into MANY.
			One is the possibility of exploring all shifts which do not decrease the alignment score instead of using heuris 153 PBML 93 JANUARY 2010 tics.
			This has been done by (Rosti et al., 2009) and provided good results (even though the increasing time of processing was not indicated).
			Another feature would be the intra-paraphrase word alignment.
			Like is presented in ﬁgure 2, when a paraphrase is found, it appears that the word alignment inside that paraphrase is not always the best.
			In that example, (supper is aligned with the instead of dinner, which would be better.
			This could be easily added using a speciﬁc alignment model.
			As mentioned before, the load of a n-gram (whatever is n) language model has to be added.
			In some cases, that can be faster than using a LM server.
			An alternative to the token pass decoder would be the use of Minimum Bayesian Risk decoder applied on the ﬁnal lattice (MBR-Lattice) like described in (Tromble et al., 2008)
	
	
			One might notice that the performance of a system combination is highly dependent of the input hypotheses (in terms of number of hypotheses, complementarity of the systems which provide them, and of course quality), the parameters of the alignment module and the language model used to decode the lattice.
			The tuning of all parameters plays consequently a big role in the quality of this kind of approach.
			As an example, in (Rosti et al., 2009), after the creation of the lattice, three iterations of tuning have been done in order to obtain good results.
			This kind of tuning procedure is not currently implemented in that software, but it is a very important step which should not be underestimated.
	
	

