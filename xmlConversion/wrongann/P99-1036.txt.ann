T3 Reference 6644 6923 The probabilities P( <U-t>lwi_I) can be esti­ mated from the relative frequencies in the training corpus whose infrequent words are replaced with their corresponding unknown word tags based on their part of speeches 2 • Table 1 shows examples of word bigrams including unknown wo
A1 RefType T3 Direct
A2 Type T3 Table
A3 Num T3 1
T4 Reference 11467 11542 Table 2: Character type configuration of infrequent words in the EDR corpus
A4 RefType T4 Direct
A5 Type T4 Table
A6 Num T4 2
T5 Reference 11543 11856 Table 3: Examples of common character bigrams for each part of speech in the infrequent words pa rt of sp ee ch ch ar ac ter bi gr a m fre qu en cy no un nu m be r a dj e ct iv al v er b v er b ad je cti ve ad ve rb < e o w > <b o w > 1 S " J < e o w > I t < e o w > L < e o w > < e o w > 13 43 4 8 4 3 2 7 2 1 3 
A7 RefType T5 Direct
A8 Type T5 Table
A9 Num T5 3
T6 Reference 13369 13483 Table 2 shows the distribution of character type sequences that constitute the infrequent words in the EDR corpus.
A10 RefType T6 Direct
A11 Type T6 Table
A12 Num T6 2
T7 Reference 11913 12047 Figure 2 shows the word length distribution of words consists of only kanji characters and words consists of only katakana characters.
A13 RefType T7 Direct
A14 Type T7 Figure
A15 Num T7 2
T8 Reference 12235 12299 Figure 1 is, in fact, a weighted sum of these two distributions.
A16 RefType T8 Direct
A17 Type T8 Figure
A18 Num T8 1
T9 Reference 14621 14740 Table 3 shows examples of common char­ acter bigrams for each part of speech in the infre­ quent words of the EDR corpu
A19 RefType T9 Direct
A20 Type T9 Table
A21 Num T9 3
T10 Reference 14746 14830 The first example in Table 3 shows that words ending in ' -' are likely to be nouns.
A22 RefType T10 Direct
A23 Type T10 Table
A24 Num T10 3
T11 Reference 19295 19386 Table 4 shows the number of sentences, words, and characters of the training and test sets.
A25 RefType T11 Direct
A26 Type T11 Table
A27 Num T11 4
T12 Reference 20754 20849 Table 5 shows the cross entropy per word and char­ acter perplexity of three unknown word model
A28 RefType T12 Direct
A29 Type T12 Table
A30 Num T12 5
T13 Reference 21553 21674 Table 5 shows that by changing the word spelling model from zerogram to bigram, character perplex­ ity is greatly reduced
A31 RefType T13 Direct
A32 Type T13 Table
A33 Num T13 5
T14 Reference 21978 22075 Figure 3 shows the part of speech prediction accu­ racy of two unknown word model without context
A34 RefType T14 Direct
A35 Type T14 Figure
A36 Num T14 3
T15 Reference 23024 23112 As Figure 3 shows, word type information improves the prediction accuracy significantly.
A37 RefType T15 Direct
A38 Type T15 Figure
A39 Num T15 3
T16 Reference 24454 24543 Table 6 shows the word segmentation accuracy of four unknown word models over test set-2.
A40 RefType T16 Direct
A41 Type T16 Table
A42 Num T16 6
T17 Reference 24995 25021 Table 7 shows the results.
A43 RefType T17 Direct
A44 Type T17 Table
A45 Num T17 7
T18 Reference 25543 25595 Table 8 shows the tagging accuracy of unknown words.
A46 RefType T18 Direct
A47 Type T18 Table
A48 Num T18 8
T19 Reference 25933 26088 Table 8 shows that by using word type and part of speech information, recall is improved from 28.1% to 40.6% and precision is improved from 57.3% to 64.1%.
A49 RefType T19 Direct
A50 Type T19 Table
A51 Num T19 8
T20 Reference 26404 26474 Table 8 shows that tagging precision is im­ proved from 88.2% to 96.6%
A52 RefType T20 Direct
A53 Type T20 Table
A54 Num T20 8
T21 Reference 28699 28874 Table 8: Part of speech tagging accuracy of unknown words (the last column represents the percentage of correctly tagged unknown words in the correctly segmented unknown words
A55 RefType T21 Direct
A56 Type T21 Table
A57 Num T21 8
T22 Reference 10999 11217 Figure 1shows the word length distribution of in­ frequent words in the EDR corpus, and the estimate of word length distribution by Equation (6) whose parameter (.A = 4.8) is the average word length of infrequent words
A58 RefType T22 Direct
A59 Type T22 Figure
A60 Num T22 1
T23 Reference 10810 10995 Figure 2: Word length distribution of kanji words and katakana words length model does not reflect the variation of the word length distribution resulting from the Japanese orthography.
A61 RefType T23 Direct
A62 Type T23 Figure
A63 Num T23 2
T24 Reference 9277 9369 Figure 1: Word length distribution of unknown words and its estimate by Poisson distribution
A64 RefType T24 Direct
A65 Type T24 Figure
A66 Num T24 1
T25 Reference 8680 8773 This is because the lefthand side of Equation (7) represents the probability of the string c1
A67 RefType T25 Direct
A68 Type T25 Equation
A69 Num T25 7
T26 Reference 8564 8675 Probabilities We find that Equation (7) assigns too little proba­ bilities to long words (5 or more characters)
A70 RefType T26 Direct
A71 Type T26 Equation
A72 Num T26 7
T1 Reference 3698 3768 Table 1: Examples of word bigrams including un­ known word tags exampl
A73 RefType T1 Direct
A74 Type T1 Table
A75 Num T1 1
T2 Reference 3916 3975 As Table 1 shows, word bigrams whose infrequent word bigram
A76 RefType T2 Direct
A77 Type T2 Table
A78 Num T2 1
T27 Reference 16647 16740 The second factor of Equation (13) is estimated from the Poisson distribution whose parameter
A79 RefType T27 Direct
A80 Type T27 Equation
A81 Num T27 13
T28 Reference 17060 17213 To compute the third factor of Equation (13), we have to estimate the character bigram probabilities that are classified by word type and part of speech.
A82 RefType T28 Direct
A83 Type T28 Equation
A84 Num T28 13
T29 Reference 20854 20961 The first model is Equation (5), which is the combina . tion of Poisson distribution and character zerogram
A85 RefType T29 Direct
A86 Type T29 Equation
A87 Num T29 5
T30 Reference 21123 21236 The third model is Equation (11), which is a set of word models trained for each word type (WT +Poisson+ bigram).
A88 RefType T30 Direct
A89 Type T30 Equation
A90 Num T30 11
T31 Reference 20987 21082 The second model is the combination of Poisson distribution (Equation (6)) and character bigram
A91 RefType T31 Direct
A92 Type T31 Equation
A93 Num T31 6
T32 Reference 21083 21118 (Equation (7)) (Poisson + hi­ gram)
A94 RefType T32 Direct
A95 Type T32 Equation
A96 Num T32 7
T33 Reference 22155 22257 Equation (12), which is a set of word models trained for each part of speech (POS + Poisson + bigram).
A97 RefType T33 Direct
A98 Type T33 Equation
A99 Num T33 12
T34 Reference 22261 22338 The second model is Equa­ tion (13), which is a set of word models trained fo
A100 RefType T34 Direct
A101 Type T34 Equation
A102 Num T34 13
T35 Reference 27979 28111 However, the spelling model, especially the character bigrams in Equation (17) are hard to es­ timate because of the data sparseness
A103 RefType T35 Direct
A104 Type T35 Equation
A105 Num T35 17
T36 Reference 26169 26187 (prec2 in Table 8)
A106 RefType T36 Direct
A107 Type T36 Table
A108 Num T36 8
T37 Reference 15935 16130 Table 4: The amount of training and test sets The first factor in the righthand side of Equa­ tion (13) is estimated from the relative frequency of the corresponding events in the training corpus
A109 RefType T37 Direct
A110 Type T37 Table
A111 Num T37 4
T38 Reference 19801 20062 As for the unknown word model, word-based char­ acter bigrams are computed from the words with Table 5: Cross entropy (CE) per word and character perplexity (PP) of each unknown word model Part of Speech Estimation Accuracy 0.95 0.9 frequency one (49,653 words)
A112 RefType T38 Direct
A113 Type T38 Table
A114 Num T38 5
T39 Reference 23822 24076 We set Table 6: Word segmentation accuracy of all words r e c pr ec F Po iss on +b igr a m W T +P oi ss on +b igr a m P O S + Po iss on +b igr a m P O S + W T + Po iss on + bi gr a m 94 .5 94 .4 94 .4 94 .6 93 .1 93 .8 93 .6 93 .7 93 .8 94 .1 94 .0 94 .1
A115 RefType T39 Direct
A116 Type T39 Table
A117 Num T39 6
T40 Reference 24077 24293 Table 7: Word segmentation accuracy of unknown words r e c pr ec F Po iss on + bi gr a m W T + P oi ss o n + b i g r a m P O S + P o is s o n + b i g r a m P O S + W T + P o is s o n + bi g ra m 31 .8 45 .5 39 .7 42.
A118 RefType T40 Direct
A119 Type T40 Table
A120 Num T40 7
T41 Reference 22403 22515 Figure 3: Accuracy of part of speech estimation each part of speech and word type (POS + WT + Poisson + bigram).
A121 RefType T41 Direct
A122 Type T41 Figure
A123 Num T41 3
T42 Reference 10293 10383 Throughout in this paper, we used Equation (9) to compute the word spelling probabilities.
A124 RefType T42 Direct
A125 Type T42 Equation
A126 Num T42 9
T43 Reference 10425 10573 Length Distribution In word segmentation, one of the major problems of the word length model of Equation (6) is the decom­ position of unknown words
A127 RefType T43 Direct
A128 Type T43 Equation
A129 Num T43 6
T44 Reference 15106 15445 By introducing the distinction of word type to the model of Equation(12),we can derive a more sophis­ ticated unknown word model that reflects both word 3 When a Chinese character is used to represent a seman­ tically equivalent Japanese verb, its root is written in the Chinese character and its inflectional suffix is written in hi­ raga
A130 RefType T44 Direct
A131 Type T44 Equation
A132 Num T44 12
T45 Reference 16029 16131 tion (13) is estimated from the relative frequency of the corresponding events in the training corpus.
A133 RefType T45 Direct
A134 Type T45 Equation
A135 Num T45 13
